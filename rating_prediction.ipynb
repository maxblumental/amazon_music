{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844ac8f7",
   "metadata": {},
   "source": [
    "# Music rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1d3cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd64f4f9358246c3ac6873098f238028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1584082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_JSON = \"Digital_Music.json\"\n",
    "\n",
    "with open(DATA_JSON, 'r') as infile:\n",
    "    entries = [json.loads(entry) for entry in tqdm(infile.read().strip().split('\\n'))]\n",
    "\n",
    "raw = pd.DataFrame(entries)\n",
    "\n",
    "raw_df = raw.sort_values('unixReviewTime').drop_duplicates(['reviewerID', 'asin'], keep='last')\n",
    "raw_df = raw_df[['reviewerID', 'asin', 'overall', 'unixReviewTime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00896f60",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "1. Remove \"vague\" elements to improve collaborative filtering. A \"vague\" element is an element that took part in too few interactions, i.e. has too few corresponding non-zero elements in the utility matrix.\n",
    "2. Split the data onto train and test \"by user\" as suggested in [the book](https://www.manning.com/books/practical-recommender-systems), section 9.8.1:\n",
    "> The last option we’ll look at doesn’t divide the users between test and training sets.\n",
    "Instead, you’ll divide each user’s ratings between a training set and a test set. The ratings will be divided by taking the first n ratings in the training set and the rest in the\n",
    "testing set.\n",
    "\n",
    "*Notes*\n",
    "* We will sacrifice a significant amount of items and users with too little information about them.\n",
    "* The splitting involves timestamps. In train split each user has the first $n$ reviews. In test split users have all subsequent items, i.e. $n+1^{st}$, $n+2^{nd}, \\ldots$. Users with $< n$ items will be present just in train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171bee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "# of vague users: 797597\n",
      "# of vague items: 192724\n",
      "iteration 1\n",
      "# of vague users: 21543\n",
      "# of vague items: 5038\n",
      "iteration 2\n",
      "# of vague users: 2244\n",
      "# of vague items: 900\n",
      "iteration 3\n",
      "# of vague users: 522\n",
      "# of vague items: 221\n",
      "iteration 4\n",
      "# of vague users: 127\n",
      "# of vague items: 41\n",
      "iteration 5\n",
      "# of vague users: 32\n",
      "# of vague items: 14\n",
      "iteration 6\n",
      "# of vague users: 10\n",
      "# of vague items: 6\n",
      "iteration 7\n",
      "# of vague users: 2\n",
      "# of vague items: 1\n",
      "iteration 8\n",
      "# of vague users: 0\n",
      "# of vague items: 0\n",
      "what's left:\n",
      "- 8.1% of ratings\n",
      "- 2.2% of unique items\n",
      "- 1.5% of unique users\n",
      "\n",
      "train/val/test ratio is 63%/19%/19%\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import drop_vague_elements, split_by_user\n",
    "\n",
    "# we could use less restrictive value of min_ratings, e.g. 2 or 3,\n",
    "# but it would be too much data for KNN methods \n",
    "# which try to build a |U|x|U| matrix\n",
    "df = drop_vague_elements(raw_df, min_ratings=5)\n",
    "\n",
    "train_df, val_test_df = split_by_user(df, train_ratings_num=7)\n",
    "\n",
    "mask = np.random.rand(len(val_test_df)) < 0.5\n",
    "val_df = val_test_df[mask]\n",
    "test_df = val_test_df[~mask]\n",
    "\n",
    "print()\n",
    "total = len(df)\n",
    "train_share = len(train_df) / total\n",
    "val_share = len(val_df) / total\n",
    "test_share = len(test_df) / total\n",
    "\n",
    "print(f\"train/val/test ratio is {train_share:.0%}/{val_share:.0%}/{test_share:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534be19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "surprise_format = ['reviewerID', 'asin', 'overall']\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train = Dataset.load_from_df(train_df[surprise_format], reader)\n",
    "val = Dataset.load_from_df(val_df[surprise_format], reader)\n",
    "test = Dataset.load_from_df(test_df[surprise_format], reader)\n",
    "\n",
    "trainset = train.build_full_trainset()\n",
    "valset = val.build_full_trainset().build_testset()\n",
    "testset = test.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc4a94",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD, NormalPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed519356",
   "metadata": {},
   "source": [
    "### Normal Predict\n",
    "\n",
    "#### Idea\n",
    "1. Model the true distribution of ratings with a gaussian $\\mathcal{N}$.\n",
    "1. Predict ratings by randomly sampling them from $\\mathcal{N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb6d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9081\n"
     ]
    }
   ],
   "source": [
    "algo = NormalPredictor()\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(valset)\n",
    "_ = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903626d",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cfa41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 10, 'n_epochs': 40, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "CPU times: user 1.14 s, sys: 525 ms, total: 1.67 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': [10],\n",
    "    'n_epochs': [40],\n",
    "    'lr_all': [0.01],\n",
    "    'reg_all': [0.1],\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=4, n_jobs=-1)\n",
    "gs.fit(train)\n",
    "\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24dc6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6039\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors=10, n_epochs=40, lr_all=0.01, reg_all=0.1)\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(valset)\n",
    "_ = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698fd03",
   "metadata": {},
   "source": [
    "### KNN algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3644a1",
   "metadata": {},
   "source": [
    "All KNN algorithms boil down to taking a weighted average of ratings. To dive into the details, let's first introduce some notation.\n",
    "\n",
    "$N_u^k(i)$ - $k$ neighbours of item $i$ which were also rated by user $u$\n",
    "\n",
    "$N_i^k(u)$ - $k$ neighbours of user $u$ who also rated item $i$\n",
    "\n",
    "Now, we can write down how to find a rating with KNN-approach in the most simple form (`KNNBasic`):\n",
    "$$r_{ui} = \\frac{\\sum_{v \\in N_i^k(u)} \\textrm{sim}(u, v) \\cdot r_{vi}}{\\sum_{v \\in N_i^k(u)} \\textrm{sim}(u, v)}$$\n",
    "\n",
    "$$\\textrm{or alternatively}$$\n",
    "\n",
    "$$r_{ui} = \\frac{\\sum_{j \\in N_u^k(i)} \\textrm{sim}(i, j) \\cdot r_{uj}}{\\sum_{j \\in N_u^k(i)} \\textrm{sim}(i, j)}$$\n",
    "\n",
    "Here $sim(u, v)$ measures how similar utility matrix rows of users $u$ and $v$ are. Same thing for $sim(i, j)$.\n",
    "\n",
    "Further modifications of `KNNBasic` - `KNNWithMeans` and `KNNWithZScore` - address the problem of \"inherently kind\" and \"inherently angry\" reviewers by subtracting means from the ratings being weighted. In addition, `KNNWithZScore` takes into account the variance of a user's (or an item's) ratings.\n",
    "\n",
    "Finally, instead of subtracting means for centering one may subtract some fancy baselines described in [a paper by Yehuda Koren](https://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf). This is implemented in `KNNBaseline`. **NB**: it is advised to use pearson-baseline similarity with `KNNBaseline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8430d",
   "metadata": {},
   "source": [
    "#### Test with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8604fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff34080b0dd46a3a80257f3dc10dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>fit_time_sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.6238</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.6265</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.6895</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.7787</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rmse  fit_time_sec\n",
       "algo                               \n",
       "KNNWithMeans   0.6238           4.5\n",
       "KNNWithZScore  0.6265           8.6\n",
       "KNNBaseline    0.6895           4.0\n",
       "KNNBasic       0.7787           4.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "import time\n",
    "\n",
    "knn_algos = [KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore]\n",
    "\n",
    "results = []\n",
    "for KNNAlgo in tqdm(knn_algos):\n",
    "    algo = KNNAlgo(verbose=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    algo.fit(trainset)\n",
    "    elapsed_time = time.time() - start\n",
    "\n",
    "    predictions = algo.test(valset)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    \n",
    "    results.append({\n",
    "        'algo': str(KNNAlgo).strip(\"<>' \").split('.')[-1],\n",
    "        'rmse': round(rmse, 4),\n",
    "        'fit_time_sec': round(elapsed_time, 1),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results).set_index('algo').sort_values(['rmse' , 'fit_time_sec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bd51e",
   "metadata": {},
   "source": [
    "Now let's properly tune `KNNBaseline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed519bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bsl_options': {'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.01, 'n_epochs': 20}, 'sim_options': {'name': 'pearson', 'user_based': False}, 'verbose': False}\n",
      "CPU times: user 15 s, sys: 7.29 s, total: 22.3 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'bsl_options': {\n",
    "        'method': ['sgd'], \n",
    "        'learning_rate': [0.01], \n",
    "        'reg': [0.01], \n",
    "        'n_epochs': [20],\n",
    "    },\n",
    "    'sim_options': {\n",
    "        'name': ['pearson'],\n",
    "        'user_based': [False],\n",
    "    },\n",
    "    'verbose': [False]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse'])\n",
    "gs.fit(train)\n",
    "\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ff166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6055\n"
     ]
    }
   ],
   "source": [
    "algo = KNNBaseline(\n",
    "    bsl_options={'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.01, 'n_epochs': 20}, \n",
    "    sim_options={'name': 'pearson', 'user_based': False}, \n",
    "    verbose=False\n",
    ")\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(valset)\n",
    "_ = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55ba5a",
   "metadata": {},
   "source": [
    "### Test the best recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b9307",
   "metadata": {},
   "source": [
    "According to my experiments, SVD and KNNBaseline demonstrate comparable performance, but SVD seems to be slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bddae",
   "metadata": {},
   "source": [
    "#### Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f735f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5885\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors=10, n_epochs=40, lr_all=0.01, reg_all=0.1)\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "_ = accuracy.rmse(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
